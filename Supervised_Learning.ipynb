{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Beta Bank's customers leaving, I've been tasked with creating a model that can predict whether a customer will leave the bank soon. I will build a model with the highest F1 score I can make, and also measure the ROC-AUC metric to compare to the F1 score.\n",
    "\n",
    "First, I will import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will download the dataset and then check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "print(duplicates.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no duplicates within the dataframe, I'll begin defining the features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['Exited', 'RowNumber', 'CustomerId', 'Surname', 'Geography', 'Gender'])\n",
    "target = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I have some NaNs and infite values, I will convernt the NaNs into the mean of the columns, and drop the infinite values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(features.mean())\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features = features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=54321)\n",
    "\n",
    "features_remain, features_test, target_remain, target_test = train_test_split(\n",
    "    features_valid, target_valid, test_size=0.5, random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll standardize the numerical features next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_valid_scaled = scaler.transform(features_valid)\n",
    "features_test_scaled = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now investigate the balance of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of Classes:  0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes_balance = df['Exited'].value_counts()\n",
    "print(\"Balance of Classes: \", classes_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there are nearly 4x as many customers who have not exited (Class 0) than those who have exited (Class 1). This could potentially cause the model to develop a bias towards Class 0, and it may even get a high accuracy score by predicting the majority for each instance.\n",
    "\n",
    "I will now train the model without fixing the class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=54321)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=54321)\n",
    "model.fit(features_train_scaled, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the f1 and roc_auc values on the validation sets before handling the imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred_val = model.predict(features_valid_scaled)\n",
    "f1_valid = f1_score(target_valid, target_pred_val)\n",
    "prob_valid = model.predict_proba(features_valid_scaled)\n",
    "prob_valid_one = prob_valid[:, 1]\n",
    "roc_auc_valid = roc_auc_score(target_valid, prob_valid_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on validation set before fixing imbalances: 0.5737439222042139\n",
      "ROC-AUC Score on validation set before fixing imbalances: 0.8501051122790255\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score on validation set before fixing imbalances:\", f1_valid)\n",
    "print(\"ROC-AUC Score on validation set before fixing imbalances:\", roc_auc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already before adjusting the imbalances, the F1 score is close to 0.59. Now I'll deal with the imbalance of classes.\n",
    "First, I'll make an upsample function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll use the upsample function on the validation sets to get a more balanced result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on validation set after fixing imbalances: 0.6022727272727273\n",
      "ROC-AUC Score on validation set after fixing imbalances: 0.8522973403408186\n"
     ]
    }
   ],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "model = RandomForestClassifier(random_state=54321)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "predicted_valid_upsampled = model.predict(features_valid)\n",
    "f1_upsampled = f1_score(target_valid, predicted_valid_upsampled)\n",
    "roc_auc_upsampled = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "print(\"F1 Score on validation set after fixing imbalances:\", f1_upsampled)\n",
    "print(\"ROC-AUC Score on validation set after fixing imbalances:\", roc_auc_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do the same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on the test set: 0.695994747209455\n",
      "ROC-AUC Score on the test set: 0.864057583587015\n"
     ]
    }
   ],
   "source": [
    "features_test_up, target_test_up = upsample(features_test, target_test, 10)\n",
    "\n",
    "predicted_test = model.predict(features_test_up)\n",
    "\n",
    "f1_test = f1_score(target_test_up, predicted_test)\n",
    "roc_auc_test = roc_auc_score(target_test_up, model.predict_proba(features_test_up)[:, 1])\n",
    "\n",
    "print(\"F1 Score on the test set:\", f1_test)\n",
    "print(\"ROC-AUC Score on the test set:\", roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will make a function to downsample the data and see if this provides a better F1 and AUC-ROC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    \n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on validation set after fixing imbalances: 0.542608695652174\n",
      "ROC-AUC Score on validation set after fixing imbalances: 0.8502341137123746\n"
     ]
    }
   ],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.2)\n",
    "\n",
    "model = RandomForestClassifier(random_state=54321)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "predicted_valid_downsampled = model.predict(features_valid)\n",
    "f1_downsampled = f1_score(target_valid, predicted_valid_downsampled)\n",
    "roc_auc_downsampled = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "print(\"F1 Score on validation set after fixing imbalances:\", f1_downsampled)\n",
    "print(\"ROC-AUC Score on validation set after fixing imbalances:\", roc_auc_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use the test set with the downsample function to see if it improves the F1 score any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on the test set: 0.7857142857142858\n",
      "ROC-AUC Score on the test set: 0.8592399308445924\n"
     ]
    }
   ],
   "source": [
    "features_test_down, target_test_down = downsample(features_test, target_test, 0.2)\n",
    "\n",
    "predicted_test = model.predict(features_test_down)\n",
    "\n",
    "f1_test = f1_score(target_test_down, predicted_test)\n",
    "roc_auc_test = roc_auc_score(target_test_down, model.predict_proba(features_test_down)[:, 1])\n",
    "\n",
    "print(\"F1 Score on the test set:\", f1_test)\n",
    "print(\"ROC-AUC Score on the test set:\", roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a few things we can comment on with these models. The F1 Score and the ROC-AUC Score were higher on the upsampled training sets than with the downsampled training sets. But when we decided to test the model, while the ROC-AUC Scores were very close to one another, the F1 Score was drastically higher in the downsampled test set. \n",
    "\n",
    "Based on the F1 Score, we can conclude that each model is working reasonably well at identifying customers at risk of leaving, with the downsampled testing set coming out on top. The ROC-AUC Score is quite high for both models, showing that it has a good chance of distinguishing between customers who will, and who will not, leave."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
